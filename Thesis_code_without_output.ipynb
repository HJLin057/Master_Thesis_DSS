{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "hVO8_IPWISeY",
      "metadata": {
        "id": "hVO8_IPWISeY"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HZ2r-85fCpP_",
      "metadata": {
        "id": "HZ2r-85fCpP_"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np, random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import os\n",
        "import kagglehub\n",
        "import cv2\n",
        "import pywt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers, callbacks, optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "import gc\n",
        "\n",
        "from typing import Dict, Any\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e075ea",
      "metadata": {
        "id": "90e075ea"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set path\n",
        "path = kagglehub.dataset_download(\"xhlulu/140k-real-and-fake-faces\")\n",
        "dataset_dir = path + \"/real_vs_fake/real-vs-fake\"\n",
        "\n",
        "print(\"Data directory:\", dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G07_8RxR472M",
      "metadata": {
        "id": "G07_8RxR472M"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 128\n",
        "SEED = 42\n",
        "CHANNELS = 3\n",
        "INITIAL_LR = 1e-4\n",
        "TOTAL_IMAGE_COUNT = 140000\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED); random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cwG4uA-iuhhj",
      "metadata": {
        "id": "cwG4uA-iuhhj"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IJxq8aytirHY",
      "metadata": {
        "id": "IJxq8aytirHY"
      },
      "outputs": [],
      "source": [
        "# Build dataframe with file paths and labels\n",
        "all_files = []\n",
        "all_labels = []\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    split_dir = os.path.join(dataset_dir, split)\n",
        "\n",
        "    for label in [\"real\", \"fake\"]:\n",
        "        class_dir = os.path.join(split_dir, label)\n",
        "\n",
        "        for fname in os.listdir(class_dir):\n",
        "            all_files.append(os.path.join(class_dir, fname))\n",
        "            all_labels.append(label)\n",
        "\n",
        "df = pd.DataFrame({\"filename\": all_files, \"class\": all_labels})\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9yL_vylTkeb1",
      "metadata": {
        "id": "9yL_vylTkeb1"
      },
      "outputs": [],
      "source": [
        "# Randomly select 10 real and 10 fake images\n",
        "real_samples = df[df['class'] == 'real'].sample(10)\n",
        "fake_samples = df[df['class'] == 'fake'].sample(10)\n",
        "samples_df = pd.concat([real_samples, fake_samples])\n",
        "\n",
        "# Display the sample images\n",
        "plt.figure(figsize=(12,10))\n",
        "for i, row in enumerate(samples_df.itertuples()):\n",
        "    img = plt.imread(row.filename) / 255.0  # normalize\n",
        "    plt.subplot(4,5,i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(row._2)\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z7234snHIrJ3",
      "metadata": {
        "id": "z7234snHIrJ3"
      },
      "source": [
        "## Fourier transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4pN_vwvnkfy",
      "metadata": {
        "id": "d4pN_vwvnkfy"
      },
      "outputs": [],
      "source": [
        "# Perform fourier transform and display\n",
        "plt.figure(figsize=(24, 10))\n",
        "for i, row in enumerate(samples_df.itertuples()):\n",
        "    img = plt.imread(row.filename) / 255.0  # normalize\n",
        "    gray = np.mean(img, axis=2) # convert to grayscale\n",
        "    f = np.fft.fft2(gray)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "    magnitude_spectrum = np.log(1 + np.abs(fshift)) # perform fourier transform\n",
        "\n",
        "    # Left: original image; Right: Fourier magnitude spectrum\n",
        "    plt.subplot(4, 10, 2*i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"{row._2}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(4, 10, 2*i+2)\n",
        "    plt.imshow(magnitude_spectrum, cmap='gray')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dEEYPor5IwcX",
      "metadata": {
        "id": "dEEYPor5IwcX"
      },
      "source": [
        "## Wavelet transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MhhY0k2jqnzH",
      "metadata": {
        "id": "MhhY0k2jqnzH"
      },
      "outputs": [],
      "source": [
        "# Perform wavelet transform and display\n",
        "plt.figure(figsize=(12,10))\n",
        "for i, row in enumerate(samples_df.itertuples()):\n",
        "    # read and normalize\n",
        "    img = plt.imread(row.filename) / 255.0\n",
        "    gray = np.mean(img, axis=2)\n",
        "\n",
        "    # 2D Discrete Wavelet Transform (Haar)\n",
        "    coeffs2 = pywt.dwt2(gray, 'haar')\n",
        "    LL, (LH, HL, HH) = coeffs2\n",
        "\n",
        "    # Show original + 4 sub-bands\n",
        "    plt.subplot(5, 5, i*5 % 25 + 1); plt.imshow(img); plt.title(f\"{row._2}\"); plt.axis(\"off\")\n",
        "    plt.subplot(5, 5, i*5 % 25 + 2); plt.imshow(LL, cmap='gray'); plt.title(\"LL\"); plt.axis(\"off\")\n",
        "    plt.subplot(5, 5, i*5 % 25 + 3); plt.imshow(LH, cmap='gray'); plt.title(\"LH\"); plt.axis(\"off\")\n",
        "    plt.subplot(5, 5, i*5 % 25 + 4); plt.imshow(HL, cmap='gray'); plt.title(\"HL\"); plt.axis(\"off\")\n",
        "    plt.subplot(5, 5, i*5 % 25 + 5); plt.imshow(HH, cmap='gray'); plt.title(\"HH\"); plt.axis(\"off\")\n",
        "\n",
        "    if (i+1) % 5 == 0:\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "urD9KuY5JJeH",
      "metadata": {
        "id": "urD9KuY5JJeH"
      },
      "source": [
        "## Real image example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y8JFf1pQv87H",
      "metadata": {
        "id": "y8JFf1pQv87H"
      },
      "outputs": [],
      "source": [
        "img_path = \"/content/drive/MyDrive/111\" # a 1024*1024 real image from original FFHQ dataset\n",
        "img = plt.imread(img_path)\n",
        "gray = np.mean(img, axis=2)\n",
        "\n",
        "# fourier transform\n",
        "f = np.fft.fft2(gray)\n",
        "fshift = np.fft.fftshift(f)\n",
        "magnitude = np.log(1 + np.abs(fshift))\n",
        "\n",
        "# wavelet transfrom\n",
        "coeffs2 = pywt.dwt2(gray, 'haar')\n",
        "LL, (LH, HL, HH) = coeffs2\n",
        "\n",
        "plt.figure(figsize=(8,12))\n",
        "plt.subplot(3,2,1); plt.imshow(img); plt.title('Original Image'); plt.axis(\"off\")\n",
        "plt.subplot(3,2,2); plt.imshow(magnitude, cmap='gray'); plt.title('Fourier transform'); plt.axis(\"off\")\n",
        "plt.subplot(3,2,3); plt.imshow(LL, cmap='gray'); plt.title('LL'); plt.axis(\"off\")\n",
        "plt.subplot(3,2,4); plt.imshow(LH, cmap='gray'); plt.title('LH'); plt.axis(\"off\")\n",
        "plt.subplot(3,2,5); plt.imshow(HL, cmap='gray'); plt.title('HL'); plt.axis(\"off\")\n",
        "plt.subplot(3,2,6); plt.imshow(HH, cmap='gray'); plt.title('HH'); plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k17-FaXSsnsJ",
      "metadata": {
        "id": "k17-FaXSsnsJ"
      },
      "source": [
        "## Mean and STD of Wavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FL1uGWPxfvGz",
      "metadata": {
        "id": "FL1uGWPxfvGz"
      },
      "outputs": [],
      "source": [
        "CHANNELS = 9\n",
        "SAMPLING_FRACTION = 0.1\n",
        "\n",
        "def compute_wavelet_features_np(np_image):\n",
        "    \"\"\"Computes and stacks 9 high-frequency DWT subbands for a SINGLE image (uint8 NumPy array).\"\"\"\n",
        "\n",
        "    wavelet_features = []\n",
        "\n",
        "    for i in range(3):\n",
        "        channel = np_image[:, :, i]\n",
        "        coeffs = pywt.dwt2(channel, 'haar')\n",
        "        LH, HL, HH = coeffs[1]\n",
        "        wavelet_features.extend([LH, HL, HH])\n",
        "\n",
        "    wavelet_stack = np.stack(wavelet_features, axis=-1)\n",
        "    return wavelet_stack\n",
        "\n",
        "df_sample = df.sample(frac=SAMPLING_FRACTION, random_state=42)\n",
        "total_sample_size = len(df_sample)\n",
        "print(f\"Sampling {total_sample_size} images ({SAMPLING_FRACTION*100:.0f}% of total) for Wavelet stats...\")\n",
        "\n",
        "all_wavelet_pixels = []\n",
        "total_pixels_processed = 0\n",
        "\n",
        "# Access the image path directly from the row value, as the index is the row identifier.\n",
        "for index, row in tqdm(df_sample.iterrows(), total=total_sample_size):\n",
        "    img_path = row.iloc[0]\n",
        "    image = cv2.imread(img_path)\n",
        "\n",
        "    wavelet_features = compute_wavelet_features_np(image)\n",
        "\n",
        "    reshaped_data = wavelet_features.reshape(-1, CHANNELS)\n",
        "    all_wavelet_pixels.append(reshaped_data)\n",
        "    total_pixels_processed += reshaped_data.shape[0]\n",
        "\n",
        "combined_data = np.concatenate(all_wavelet_pixels, axis=0)\n",
        "print(f\"Total {combined_data.shape[0]} pixel samples aggregated.\")\n",
        "\n",
        "Wavelet_MEAN_NP = np.mean(combined_data, axis=0).astype(np.float32)\n",
        "Wavelet_STD_NP = np.std(combined_data, axis=0).astype(np.float32)\n",
        "\n",
        "print(f\"Wavelet_MEAN = tf.constant({Wavelet_MEAN_NP.tolist()}, dtype=tf.float32)\")\n",
        "print(f\"Wavelet_STD = tf.constant({Wavelet_STD_NP.tolist()}, dtype=tf.float32)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uYShZwzLuzn-",
      "metadata": {
        "id": "uYShZwzLuzn-"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PuIk0qu6cYuk",
      "metadata": {
        "id": "PuIk0qu6cYuk"
      },
      "source": [
        "## Dataset Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jXzOzFtJp1UT",
      "metadata": {
        "id": "jXzOzFtJp1UT"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, \"train\"),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"binary\",\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, \"valid\"),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"binary\",\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, \"test\"),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"binary\",\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cVf-NZkstTe5",
      "metadata": {
        "id": "cVf-NZkstTe5"
      },
      "outputs": [],
      "source": [
        "# Inspect one sample (image values + label)\n",
        "for img, label in train_ds:\n",
        "    print(\"Image values:\", img[0])\n",
        "    print(\"Label:\", label[0])\n",
        "    break\n",
        "\n",
        "# Check batch shapes\n",
        "for img, label in train_ds:\n",
        "    print(\"Image batch shape:\", img.shape)\n",
        "    print(\"Label batch shape:\", label.shape)\n",
        "    break\n",
        "\n",
        "# Show class-to-index mapping\n",
        "print(\"Class names:\", train_ds.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HS6sRuNT_7fI",
      "metadata": {
        "id": "HS6sRuNT_7fI"
      },
      "source": [
        "## Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wafTEwRTraAD",
      "metadata": {
        "id": "wafTEwRTraAD"
      },
      "outputs": [],
      "source": [
        "Wavelet_MEAN = tf.constant([0.06322062760591507, 0.14566604793071747, 0.004705097526311874, 0.07626466453075409, -0.05939734727144241, 0.005020765122026205, 0.02491244673728943, 0.11974337697029114, 0.004669941496104002], dtype=tf.float32)\n",
        "Wavelet_STD = tf.constant([11.035733222961426, 11.721734046936035, 7.004025459289551, 11.152276992797852, 11.841991424560547, 7.022481918334961, 11.28213119506836, 12.013513565063477, 7.008289337158203], dtype=tf.float32)\n",
        "\n",
        "# DWT Feature Extraction (pywt + tf.py_function)\n",
        "def compute_wavelet_features_py(image_tensor):\n",
        "    \"\"\"Computes and stacks 9 high-frequency DWT subbands for a SINGLE image (uint8).\"\"\"\n",
        "    # NOTE: This part is the performance bottleneck due to tf.py_function and .numpy()\n",
        "    np_image = image_tensor.numpy()\n",
        "    wavelet_features = []\n",
        "\n",
        "    for i in range(3): # Iterate through R, G, B channels\n",
        "        channel = np_image[:, :, i]\n",
        "        coeffs = pywt.dwt2(channel, 'haar')\n",
        "        # coeffs[1] contains (LH, HL, HH) high-frequency subbands\n",
        "        LH, HL, HH = coeffs[1]\n",
        "        wavelet_features.extend([LH, HL, HH])\n",
        "\n",
        "    wavelet_stack = np.stack(wavelet_features, axis=-1)\n",
        "    return tf.convert_to_tensor(wavelet_stack, dtype=tf.float32)\n",
        "\n",
        "def process_wavelet_features(images_batch):\n",
        "    \"\"\"Computes, resizes, and returns UN-NORMALIZED Wavelet features for a batch (SLOW).\"\"\"\n",
        "\n",
        "    def process_single_image_wavelet(image):\n",
        "        # image must be raw uint8 here (0-255)\n",
        "        wavelet_features_downscaled = tf.py_function(\n",
        "            compute_wavelet_features_py,\n",
        "            [image],\n",
        "            tf.float32\n",
        "        )\n",
        "        new_h, new_w = IMG_SIZE[0] // 2, IMG_SIZE[1] // 2\n",
        "        # Must set the shape for tf.data to work\n",
        "        wavelet_features_downscaled.set_shape([new_h, new_w, 9])\n",
        "\n",
        "        wavelet_features_resized = tf.image.resize(\n",
        "            wavelet_features_downscaled,\n",
        "            IMG_SIZE,\n",
        "            method='bilinear'\n",
        "        )\n",
        "        return wavelet_features_resized\n",
        "\n",
        "    # tf.map_fn applies the py_function-based logic to every image in the batch\n",
        "    wavelet_batch = tf.map_fn(\n",
        "        process_single_image_wavelet,\n",
        "        images_batch,\n",
        "        fn_output_signature=tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 9), dtype=tf.float32),\n",
        "    )\n",
        "\n",
        "    wavelet_batch_standardized = (wavelet_batch - Wavelet_MEAN) / (Wavelet_STD + 1e-7)\n",
        "\n",
        "    return wavelet_batch_standardized\n",
        "\n",
        "# Data Augmentation and Preprocessing Functions\n",
        "def apply_augmentation(images_batch):\n",
        "    \"\"\"Apply Random Horizontal Flip and Additive Gaussian Noise to raw RGB batch (0-255).\"\"\"\n",
        "    augmented_images = tf.image.random_flip_left_right(images_batch)\n",
        "    float_images = tf.cast(augmented_images, tf.float32)\n",
        "    NOISE_STDDEV = 5.0\n",
        "\n",
        "    noise = tf.random.normal(shape=tf.shape(float_images), mean=0.0, stddev=NOISE_STDDEV, dtype=tf.float32)\n",
        "    noisy_images = tf.clip_by_value(float_images + noise, 0.0, 255.0)\n",
        "\n",
        "    return tf.cast(noisy_images, images_batch.dtype)\n",
        "\n",
        "\n",
        "# RGB ONLY Preprocessing (3 Channels)\n",
        "def preprocess_rgb_only_train(images_batch, labels_batch):\n",
        "    augmented_images_batch = apply_augmentation(images_batch)\n",
        "    return tf.cast(augmented_images_batch, tf.float32) / 255.0, labels_batch\n",
        "\n",
        "def preprocess_rgb_only_valid(images_batch, labels_batch):\n",
        "    return tf.cast(images_batch, tf.float32) / 255.0, labels_batch\n",
        "\n",
        "\n",
        "# WAVELETS ONLY Preprocessing (9 Channels)\n",
        "def preprocess_wavelet_only_train(images_batch, labels_batch):\n",
        "    augmented_images_batch = apply_augmentation(images_batch)\n",
        "    wavelet_batch = process_wavelet_features(augmented_images_batch)\n",
        "    return wavelet_batch, labels_batch\n",
        "\n",
        "def preprocess_wavelet_only_valid(images_batch, labels_batch):\n",
        "    wavelet_batch = process_wavelet_features(images_batch)\n",
        "    return wavelet_batch, labels_batch\n",
        "\n",
        "\n",
        "# RGB + WAVELETS Preprocessing (12 Channels)\n",
        "def preprocess_rgb_wavelet_train(images_batch, labels_batch):\n",
        "    augmented_images_batch = apply_augmentation(images_batch)\n",
        "    rgb_normalized_batch = tf.cast(augmented_images_batch, tf.float32) / 255.0\n",
        "    wavelet_batch = process_wavelet_features(augmented_images_batch)\n",
        "\n",
        "    combined_features_batch = tf.concat([rgb_normalized_batch, wavelet_batch], axis=-1)\n",
        "    return combined_features_batch, labels_batch\n",
        "\n",
        "def preprocess_rgb_wavelet_valid(images_batch, labels_batch):\n",
        "    rgb_normalized_batch = tf.cast(images_batch, tf.float32) / 255.0\n",
        "    wavelet_batch = process_wavelet_features(images_batch)\n",
        "    combined_features_batch = tf.concat([rgb_normalized_batch, wavelet_batch], axis=-1)\n",
        "    return combined_features_batch, labels_batch\n",
        "\n",
        "# Dataset Mapping\n",
        "train_ds_rgb = train_ds.map(preprocess_rgb_only_train, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "valid_ds_rgb = valid_ds.map(preprocess_rgb_only_valid, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds_wavelet = train_ds.map(preprocess_wavelet_only_train, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "valid_ds_wavelet = valid_ds.map(preprocess_wavelet_only_valid, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds_rgb_wavelet = train_ds.map(preprocess_rgb_wavelet_train, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "valid_ds_rgb_wavelet = valid_ds.map(preprocess_rgb_wavelet_valid, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"All datasets are prepared (using pywt + tf.py_function) and model uses Batch Normalization.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2XWgZfQsQMuj",
      "metadata": {
        "id": "2XWgZfQsQMuj"
      },
      "outputs": [],
      "source": [
        "# Test Dataset Mapping\n",
        "test_ds_rgb = test_ds.map(preprocess_rgb_only_valid, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds_wavelet = test_ds.map(preprocess_wavelet_only_valid, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds_rgb_wavelet = test_ds.map(preprocess_rgb_wavelet_valid, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lXRcTl2DcTNd",
      "metadata": {
        "id": "lXRcTl2DcTNd"
      },
      "source": [
        "## Callbacks Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rNIz8pv_eOg4",
      "metadata": {
        "id": "rNIz8pv_eOg4"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
        "\n",
        "def get_checkpoint_cb(name):\n",
        "\n",
        "    filepath = f\"/content/drive/MyDrive/Thesis/{name}_optimized_best.weights.h5\"\n",
        "    return tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MyucScRKAAIh",
      "metadata": {
        "id": "MyucScRKAAIh"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W2fdkw-Ytz0o",
      "metadata": {
        "id": "W2fdkw-Ytz0o"
      },
      "outputs": [],
      "source": [
        "def densenet_scratch(input_channels, model_name, initial_lr):\n",
        "    \"\"\"Builds DenseNet121 from scratch, including input BN for feature normalization.\"\"\"\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=initial_lr,\n",
        "        weight_decay=1e-4\n",
        "    )\n",
        "\n",
        "    base = tf.keras.applications.DenseNet121(\n",
        "        weights=None,\n",
        "        include_top=False,\n",
        "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], input_channels),\n",
        "        name=f\"densenet121_{input_channels}ch\"\n",
        "    )\n",
        "\n",
        "    # Building the model flow\n",
        "    x = base.output\n",
        "\n",
        "    # Classification Head\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=base.input, outputs=output, name=model_name)\n",
        "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def train_single_phase_optimized(model, train_ds, valid_ds, model_tag, initial_lr):\n",
        "    \"\"\"\n",
        "    Trains the model using a single, long phase with automatic LR reduction and Early Stopping.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n--- Starting {model_tag} Single Phase Optimization (LR={initial_lr}) ---\")\n",
        "\n",
        "    model.optimizer.learning_rate.assign(initial_lr)\n",
        "\n",
        "    checkpoint_cb = get_checkpoint_cb(model_tag)\n",
        "\n",
        "    callbacks_list = [checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "    TOTAL_EPOCHS = 60\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=valid_ds,\n",
        "        epochs=TOTAL_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        best_weights_path = f\"/content/drive/MyDrive/Thesis/{model_tag}_optimized_best.weights.h5\"\n",
        "        model.load_weights(best_weights_path)\n",
        "        print(f\"Loaded BEST weights from checkpoint for final model object.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load best weights from disk. Using weights restored by EarlyStopping.\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6vrBd_dM3WwN",
      "metadata": {
        "id": "6vrBd_dM3WwN"
      },
      "outputs": [],
      "source": [
        "model_rgb = densenet_scratch(3, \"rgb_only\", INITIAL_LR)\n",
        "model_rgb.load_weights(\"/content/drive/MyDrive/Thesis/rgb_only_optimized_best.weights.h5\")\n",
        "model_wavelets = densenet_scratch(9, \"wavelets_only\", INITIAL_LR)\n",
        "model_wavelets.load_weights(\"/content/drive/MyDrive/Thesis/wavelets_only_optimized_best.weights.h5\")\n",
        "model_rgb_wavelets = densenet_scratch(12, \"rgb_wavelets\", INITIAL_LR)\n",
        "model_rgb_wavelets.load_weights(\"/content/drive/MyDrive/Thesis/rgb_wavelets_optimized_best.weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uL6N2y0_Pb2K",
      "metadata": {
        "id": "uL6N2y0_Pb2K"
      },
      "source": [
        "## 1. RGB ONLY Model (3 Channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jj8XkcEVPizP",
      "metadata": {
        "id": "Jj8XkcEVPizP"
      },
      "outputs": [],
      "source": [
        "model_rgb = densenet_scratch(3, \"rgb_only\", INITIAL_LR)\n",
        "history_rgb = train_single_phase_optimized(model_rgb, train_ds_rgb, valid_ds_rgb, \"rgb_only\", INITIAL_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UzJAfvZGP1vT",
      "metadata": {
        "id": "UzJAfvZGP1vT"
      },
      "source": [
        "## 2. Wavelets ONLY Model (9 Channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MSbWD2vRP9ni",
      "metadata": {
        "id": "MSbWD2vRP9ni"
      },
      "outputs": [],
      "source": [
        "model_wavelets = densenet_scratch(9, \"wavelets_only\", INITIAL_LR)\n",
        "history_wavelets = train_single_phase_optimized(model_wavelets, train_ds_wavelet, valid_ds_wavelet, \"wavelets_only\", INITIAL_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XgHD2HxVAHTq",
      "metadata": {
        "id": "XgHD2HxVAHTq"
      },
      "source": [
        "## 3. RGB + Wavelets Model (12 Channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oHp-DD8Yu0EG",
      "metadata": {
        "id": "oHp-DD8Yu0EG"
      },
      "outputs": [],
      "source": [
        "model_rgb_wavelets = densenet_scratch(12, \"rgb_wavelets\", INITIAL_LR)\n",
        "history_rgb_wavelets = train_single_phase_optimized(model_rgb_wavelets, train_ds_rgb_wavelet, valid_ds_rgb_wavelet, \"rgb_wavelets\", INITIAL_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eWnna-M83UKV",
      "metadata": {
        "id": "eWnna-M83UKV"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A7qcPrX0JURV",
      "metadata": {
        "id": "A7qcPrX0JURV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# RGB Only\n",
        "epochs_rgb = np.arange(1, 22)\n",
        "val_acc_rgb = [0.5698,0.8039,0.6641,0.8837,0.5240,0.7947,0.9186,0.9050,0.6664,0.9146,\n",
        "               0.9646,0.9427,0.9625,0.9432,0.9753,0.9754,0.9765,0.9640,0.9790,0.9774,0.9567]\n",
        "val_loss_rgb = [1.1607,0.4665,0.9485,0.2816,2.4571,0.6526,0.2125,0.2639,1.5332,0.2655,\n",
        "                0.1048,0.1786,0.1306,0.2229,0.0772,0.0837,0.0870,0.1292,0.0780,0.0847,0.1740]\n",
        "\n",
        "# Wavelet Only\n",
        "epochs_wav = np.arange(1, 16)\n",
        "val_acc_wav = [0.5433,0.8595,0.6839,0.8429,0.7840,0.9059,0.8766,0.9564,0.9697,0.9624,\n",
        "               0.9645,0.8691,0.9387,0.9717,0.9588]\n",
        "val_loss_wav = [2.1196,0.3544,1.4302,0.4641,0.8053,0.3061,0.5417,0.1168,0.0809,0.1084,\n",
        "                0.1058,0.5942,0.2248,0.0847,0.1456]\n",
        "\n",
        "# RGB + Wavelet\n",
        "epochs_fuse = np.arange(1, 21)\n",
        "val_acc_fuse = [0.6327,0.7728,0.9048,0.7564,0.8747,0.7071,0.8768,0.9346,0.9551,0.8801,\n",
        "                0.8569,0.9366,0.9635,0.9820,0.9639,0.9143,0.9539,0.9743,0.9416,0.9767]\n",
        "val_loss_fuse = [1.2879,0.6531,0.2352,1.1157,0.3708,1.2748,0.4079,0.1918,0.1312,0.4632,\n",
        "                 0.6902,0.2180,0.1148,0.0525,0.1183,0.3935,0.1743,0.0861,0.2276,0.0840]\n",
        "\n",
        "# Stats for table\n",
        "def get_summary(name, epochs, acc, loss):\n",
        "    best_acc_idx = np.argmax(acc)\n",
        "    best_loss_idx = np.argmin(loss)\n",
        "    return [\n",
        "        name,\n",
        "        f\"{acc[best_acc_idx]:.4f} (Ep {epochs[best_acc_idx]})\",\n",
        "        f\"{loss[best_loss_idx]:.4f} (Ep {epochs[best_loss_idx]})\"\n",
        "    ]\n",
        "\n",
        "summary_data = [\n",
        "    get_summary(\"RGB Only\", epochs_rgb, val_acc_rgb, val_loss_rgb),\n",
        "    get_summary(\"Wavelets Only\", epochs_wav, val_acc_wav, val_loss_wav),\n",
        "    get_summary(\"RGB + Wavelets\", epochs_fuse, val_acc_fuse, val_loss_fuse)\n",
        "]\n",
        "\n",
        "colors = {\"RGB Only\":\"#1f77b4\", \"Wavelets Only\":\"#ff7f0e\", \"RGB + Wavelets\":\"#2ca02c\"}\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
        "plt.subplots_adjust(hspace=0.35, bottom=0.15, top=0.9)\n",
        "\n",
        "# Validation Accuracy\n",
        "axes[0].plot(epochs_rgb, val_acc_rgb, label=\"RGB Only\", color=colors[\"RGB Only\"], linewidth=2)\n",
        "axes[0].plot(epochs_wav, val_acc_wav, label=\"Wavelets Only\", color=colors[\"Wavelets Only\"], linewidth=2)\n",
        "axes[0].plot(epochs_fuse, val_acc_fuse, label=\"RGB + Wavelets\", color=colors[\"RGB + Wavelets\"], linewidth=2)\n",
        "axes[0].set_ylabel(\"Validation Accuracy\")\n",
        "axes[0].set_ylim(0.4, 1.05)\n",
        "axes[0].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "axes[0].legend(loc=\"lower right\", fontsize=9)\n",
        "axes[0].set_title(\"Validation Accuracy Comparison\")\n",
        "\n",
        "# Validation Loss\n",
        "axes[1].plot(epochs_rgb, val_loss_rgb, label=\"RGB Only\", color=colors[\"RGB Only\"], linewidth=2)\n",
        "axes[1].plot(epochs_wav, val_loss_wav, label=\"Wavelets Only\", color=colors[\"Wavelets Only\"], linewidth=2)\n",
        "axes[1].plot(epochs_fuse, val_loss_fuse, label=\"RGB + Wavelets\", color=colors[\"RGB + Wavelets\"], linewidth=2)\n",
        "axes[1].set_xlabel(\"Epoch\")\n",
        "axes[1].set_ylabel(\"Validation Loss\")\n",
        "axes[1].set_ylim(0, 2.6)\n",
        "axes[1].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "axes[1].legend(loc=\"upper right\", fontsize=9)\n",
        "axes[1].set_title(\"Validation Loss Comparison\")\n",
        "\n",
        "fig_table, ax_table = plt.subplots(figsize=(6, 1.3))\n",
        "ax_table.axis(\"off\")\n",
        "\n",
        "col_labels = [\"Model\", \"Best Val Acc\", \"Min Val Loss\"]\n",
        "the_table = ax_table.table(\n",
        "    cellText=summary_data,\n",
        "    colLabels=col_labels,\n",
        "    loc='center',\n",
        "    cellLoc='center'\n",
        ")\n",
        "the_table.auto_set_font_size(False)\n",
        "the_table.set_fontsize(9)\n",
        "the_table.scale(1.2, 1.3)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NGbk_QON4Ott",
      "metadata": {
        "id": "NGbk_QON4Ott"
      },
      "outputs": [],
      "source": [
        "# Define the evaluation configuration: Model, Name, and its corresponding Dataset\n",
        "eval_configurations = {\n",
        "    \"RGB Only\": (model_rgb, test_ds_rgb),\n",
        "    \"Wavelets Only\": (model_wavelets, test_ds_wavelet),\n",
        "    \"RGB + Wavelets\": (model_rgb_wavelets, test_ds_rgb_wavelet)\n",
        "}\n",
        "\n",
        "# Extract true labels (Y_true) once. The labels are identical across all mapped test datasets.\n",
        "Y_true = np.concatenate([y for x, y in test_ds_rgb], axis=0).astype(int).flatten()\n",
        "\n",
        "# Evaluation and Comparison\n",
        "results_df = pd.DataFrame()\n",
        "all_preds = {}\n",
        "roc_plots = {}\n",
        "T = 0.5 # Classification threshold\n",
        "\n",
        "for name, (model, dataset) in eval_configurations.items():\n",
        "\n",
        "    # Predict probabilities using the correct dataset for the model\n",
        "    Y_pred_proba = model.predict(dataset, verbose=0).flatten()\n",
        "\n",
        "    # Store binary predictions\n",
        "    Y_pred_binary = (Y_pred_proba > T).astype(int)\n",
        "    all_preds[name] = Y_pred_binary\n",
        "\n",
        "    # Calculate core metrics\n",
        "    acc = metrics.accuracy_score(Y_true, Y_pred_binary)\n",
        "    prec = metrics.precision_score(Y_true, Y_pred_binary)\n",
        "    rec = metrics.recall_score(Y_true, Y_pred_binary)\n",
        "    f1 = metrics.f1_score(Y_true, Y_pred_binary)\n",
        "\n",
        "    # Calculate AUC-ROC\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(Y_true, Y_pred_proba)\n",
        "    auc_score = metrics.auc(fpr, tpr)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame({\n",
        "        'Model': name,\n",
        "        'Accuracy': acc,\n",
        "        'Precision': prec,\n",
        "        'Recall': rec,\n",
        "        'F1 Score': f1,\n",
        "        'AUC-ROC': auc_score\n",
        "    }, index=[0])], ignore_index=True)\n",
        "\n",
        "    roc_plots[name] = (fpr, tpr, auc_score)\n",
        "\n",
        "print(\"Evaluation complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7481TsDIEIp",
      "metadata": {
        "id": "d7481TsDIEIp"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Matrics"
      ],
      "metadata": {
        "id": "WdI5QfeLlj-m"
      },
      "id": "WdI5QfeLlj-m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zkmXe-z8IDbA",
      "metadata": {
        "id": "zkmXe-z8IDbA"
      },
      "outputs": [],
      "source": [
        "# Performance Metrics Comparison\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "display(results_df.sort_values(by='AUC-ROC', ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC Curve"
      ],
      "metadata": {
        "id": "6isAWcgqlgc4"
      },
      "id": "6isAWcgqlgc4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0Rkekri_IUny",
      "metadata": {
        "id": "0Rkekri_IUny"
      },
      "outputs": [],
      "source": [
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "for name, (fpr, tpr, auc_score) in roc_plots.items():\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.4f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--') # Diagonal line for random guess\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (FPR)', fontsize=12)\n",
        "plt.ylabel('True Positive Rate (TPR)', fontsize=12)\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve Comparison', fontsize=14)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, linestyle=':', alpha=0.6)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "UpaQYtCJlcHb"
      },
      "id": "UpaQYtCJlcHb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YxRmBfdtIcvN",
      "metadata": {
        "id": "YxRmBfdtIcvN"
      },
      "outputs": [],
      "source": [
        "# Plot Confusion Matrices\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "for i, (name, Y_pred) in enumerate(all_preds.items()):\n",
        "    cm = metrics.confusion_matrix(Y_true, Y_pred)\n",
        "\n",
        "    plt.subplot(1, len(eval_configurations), i + 1)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=['Predict Fake (0)', 'Predict Real (1)'],\n",
        "                yticklabels=['Actual Fake (0)', 'Actual Real (1)'])\n",
        "    plt.title(f'CM: {name}')\n",
        "    plt.ylabel('Actual Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TO8b95usuKkr",
      "metadata": {
        "id": "TO8b95usuKkr"
      },
      "source": [
        "## Cross Validation (Stratified K Fold + Bootstrap CI + McNEMAR'S Test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9WZbaEwFfRaj",
      "metadata": {
        "id": "9WZbaEwFfRaj"
      },
      "outputs": [],
      "source": [
        "k = 10\n",
        "threshold = 0.5\n",
        "random_state = 42\n",
        "\n",
        "def collect_labels(ds):\n",
        "    ys = []\n",
        "    for _, yb in ds:\n",
        "        ys.append(np.asarray(yb))\n",
        "    return np.concatenate(ys, axis=0).astype(int).flatten()\n",
        "\n",
        "Y = collect_labels(test_ds_rgb)\n",
        "n = len(Y)\n",
        "print(\"labels:\", n)\n",
        "\n",
        "def predict_probs(model, ds):\n",
        "    probs = model.predict(ds.prefetch(tf.data.AUTOTUNE), verbose=1)\n",
        "    return np.asarray(probs).flatten()\n",
        "\n",
        "evals = {\n",
        "    \"RGB Only\": (model_rgb, test_ds_rgb),\n",
        "    \"Wavelets Only\": (model_wavelets, test_ds_wavelet),\n",
        "    \"RGB + Wavelets\": (model_rgb_wavelets, test_ds_rgb_wavelet)\n",
        "}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
        "results = []\n",
        "\n",
        "for name, (model, ds) in evals.items():\n",
        "    print(f\"\\nEvaluating: {name}\")\n",
        "    probs = predict_probs(model, ds)          # streaming predict, memory-friendly\n",
        "    if probs.shape[0] != n:\n",
        "        raise ValueError(f\"{name}: probs length {probs.shape[0]} != labels length {n}\")\n",
        "\n",
        "    fold_metrics = []\n",
        "    for _, test_idx in skf.split(np.zeros(n), Y):\n",
        "        y_true = Y[test_idx]\n",
        "        y_proba = probs[test_idx]\n",
        "        y_pred = (y_proba > threshold).astype(int)\n",
        "\n",
        "        acc = metrics.accuracy_score(y_true, y_pred)\n",
        "        prec = metrics.precision_score(y_true, y_pred, zero_division=0)\n",
        "        rec = metrics.recall_score(y_true, y_pred, zero_division=0)\n",
        "        f1 = metrics.f1_score(y_true, y_pred, zero_division=0)\n",
        "        fpr, tpr, _ = metrics.roc_curve(y_true, y_proba)\n",
        "        auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "        fold_metrics.append([acc, prec, rec, f1, auc])\n",
        "\n",
        "    fold_metrics = np.array(fold_metrics)\n",
        "    results.append([\n",
        "        name,\n",
        "        fold_metrics[:,0].mean(), fold_metrics[:,0].std(),\n",
        "        fold_metrics[:,1].mean(), fold_metrics[:,1].std(),\n",
        "        fold_metrics[:,2].mean(), fold_metrics[:,2].std(),\n",
        "        fold_metrics[:,3].mean(), fold_metrics[:,3].std(),\n",
        "        fold_metrics[:,4].mean(), fold_metrics[:,4].std(),\n",
        "    ])\n",
        "\n",
        "cols = [\"Model\",\n",
        "        \"Acc_mean\",\"Acc_std\",\"Prec_mean\",\"Prec_std\",\n",
        "        \"Rec_mean\",\"Rec_std\",\"F1_mean\",\"F1_std\",\"AUC_mean\",\"AUC_std\"]\n",
        "results_df = pd.DataFrame(results, columns=cols)\n",
        "print(\"\\nFinal results:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uGdgmBRjxbKI",
      "metadata": {
        "id": "uGdgmBRjxbKI"
      },
      "outputs": [],
      "source": [
        "# Define evaluation configurations for each model and dataset\n",
        "eval_configurations = {\n",
        "    \"RGB Only\": (model_rgb, test_ds_rgb),\n",
        "    \"Wavelets Only\": (model_wavelets, test_ds_wavelet),\n",
        "    \"RGB + Wavelets\": (model_rgb_wavelets, test_ds_rgb_wavelet)\n",
        "}\n",
        "\n",
        "N_BOOT = 1000\n",
        "TH = 0.5\n",
        "\n",
        "probs = {}\n",
        "preds_bin = {}\n",
        "Y_true = None\n",
        "\n",
        "for name, (model, dataset) in eval_configurations.items():\n",
        "    probs[name] = model.predict(dataset, verbose=0).flatten()\n",
        "    preds_bin[name] = (probs[name] > TH).astype(int)\n",
        "    if Y_true is None:\n",
        "        Y_true = np.concatenate([y for x, y in dataset], axis=0).astype(int).flatten()\n",
        "\n",
        "rows = []\n",
        "for name in probs:\n",
        "    p = preds_bin[name]\n",
        "    rows.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": metrics.accuracy_score(Y_true, p),\n",
        "        \"Precision\": metrics.precision_score(Y_true, p, zero_division=0),\n",
        "        \"Recall\": metrics.recall_score(Y_true, p, zero_division=0),\n",
        "        \"F1\": metrics.f1_score(Y_true, p, zero_division=0),\n",
        "        \"AUC\": metrics.roc_auc_score(Y_true, probs[name])\n",
        "    })\n",
        "global_df = pd.DataFrame(rows)\n",
        "\n",
        "def bootstrap_ci(y_true, y_proba, stat_fn, n_boot=N_BOOT):\n",
        "    n = len(y_true)\n",
        "    vals = []\n",
        "    for _ in range(n_boot):\n",
        "        idx = np.random.choice(n, n, replace=True)\n",
        "        yt = y_true[idx]\n",
        "        yp = y_proba[idx]\n",
        "        vals.append(stat_fn(yt, yp))\n",
        "    lo, hi = np.percentile(vals, [2.5, 97.5])\n",
        "    return np.mean(vals), lo, hi\n",
        "\n",
        "def stat_accuracy(yt, yp):\n",
        "    return metrics.accuracy_score(yt, (yp>TH).astype(int))\n",
        "def stat_precision(yt, yp):\n",
        "    return metrics.precision_score(yt, (yp>TH).astype(int), zero_division=0)\n",
        "def stat_recall(yt, yp):\n",
        "    return metrics.recall_score(yt, (yp>TH).astype(int), zero_division=0)\n",
        "def stat_f1(yt, yp):\n",
        "    return metrics.f1_score(yt, (yp>TH).astype(int), zero_division=0)\n",
        "def stat_auc(yt, yp):\n",
        "    return metrics.roc_auc_score(yt, yp)\n",
        "\n",
        "ci_rows = []\n",
        "for name in probs:\n",
        "    mean_acc, lo_acc, hi_acc = bootstrap_ci(Y_true, probs[name], stat_accuracy)\n",
        "    mean_pre, lo_pre, hi_pre = bootstrap_ci(Y_true, probs[name], stat_precision)\n",
        "    mean_rec, lo_rec, hi_rec = bootstrap_ci(Y_true, probs[name], stat_recall)\n",
        "    mean_f1, lo_f1, hi_f1 = bootstrap_ci(Y_true, probs[name], stat_f1)\n",
        "    mean_auc, lo_auc, hi_auc = bootstrap_ci(Y_true, probs[name], stat_auc)\n",
        "    ci_rows.append({\n",
        "        \"Model\": name,\n",
        "        \"Acc_mean\": mean_acc, \"Acc_95ci\": f\"{lo_acc:.4f}-{hi_acc:.4f}\",\n",
        "        \"Prec_mean\": mean_pre, \"Prec_95ci\": f\"{lo_pre:.4f}-{hi_pre:.4f}\",\n",
        "        \"Rec_mean\": mean_rec, \"Rec_95ci\": f\"{lo_rec:.4f}-{hi_rec:.4f}\",\n",
        "        \"F1_mean\": mean_f1, \"F1_95ci\": f\"{lo_f1:.4f}-{hi_f1:.4f}\",\n",
        "        \"AUC_mean\": mean_auc, \"AUC_95ci\": f\"{lo_auc:.4f}-{hi_auc:.4f}\"\n",
        "    })\n",
        "\n",
        "ci_df = pd.DataFrame(ci_rows)\n",
        "\n",
        "# McNemar test: RGB Only vs RGB + Wavelets\n",
        "a = preds_bin[\"RGB Only\"]\n",
        "b = preds_bin[\"RGB + Wavelets\"]\n",
        "\n",
        "b00 = np.sum((a==Y_true) & (b==Y_true))  # both correct\n",
        "b01 = np.sum((a==Y_true) & (b!=Y_true))  # a correct, b wrong\n",
        "b10 = np.sum((a!=Y_true) & (b==Y_true))  # a wrong, b correct\n",
        "b11 = np.sum((a!=Y_true) & (b!=Y_true))  # both wrong\n",
        "table = [[b00, b01],[b10,b11]]\n",
        "mcnemar_res = mcnemar(table, exact=False, correction=True)\n",
        "\n",
        "print(\"Global metrics:\\n\", global_df)\n",
        "print(\"\\nBootstrap CIs:\\n\", ci_df)\n",
        "print(\"\\nMcNemar (RGB Only vs RGB+Wavelets):\")\n",
        "print(\" contingency table:\", table)\n",
        "print(\" statistic=%.4f p=%.6f\" % (mcnemar_res.statistic, mcnemar_res.pvalue))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bk1A8rE1eY1W",
      "metadata": {
        "id": "bk1A8rE1eY1W"
      },
      "source": [
        "# Grad-Cam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\"RGB Only\": model_rgb, \"Wavelets Only\": model_wavelets, \"RGB + Wavelets\": model_rgb_wavelets}\n",
        "\n",
        "LAST_CONV_LAYER_NAME = \"conv5_block16_concat\"\n",
        "\n",
        "predictions = {}\n",
        "ds_map = {\"RGB Only\": test_ds_rgb, \"Wavelets Only\": test_ds_wavelet, \"RGB + Wavelets\": test_ds_rgb_wavelet}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Predicting for {name}...\")\n",
        "    pv_all = model.predict(ds_map[name], verbose=0).ravel()\n",
        "    pc_all = (pv_all >= 0.5).astype(int)\n",
        "    predictions[name] = {\"pv\": pv_all, \"pc\": pc_all}"
      ],
      "metadata": {
        "id": "CkbK_fSsXf2B"
      },
      "id": "CkbK_fSsXf2B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "MODEL_R = \"RGB Only\"\n",
        "MODEL_W = \"Wavelets Only\"\n",
        "MODEL_RW = \"RGB + Wavelets\"\n",
        "MAX_SAMPLES = 10\n",
        "\n",
        "# Initialization and Data Loading\n",
        "\n",
        "LAST_CONV_LAYER_NAME = \"conv5_block16_concat\"\n",
        "\n",
        "test_dir = os.path.join(dataset_dir, \"test\")\n",
        "paths, labels = [], []\n",
        "class_names = sorted(os.listdir(test_dir))\n",
        "\n",
        "for cls_idx, d in enumerate(class_names):\n",
        "    folder = os.path.join(test_dir, d)\n",
        "    for f in sorted(os.listdir(folder)):\n",
        "        if f.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "            paths.append(os.path.join(folder, f))\n",
        "            labels.append(cls_idx)\n",
        "\n",
        "paths = np.array(paths)\n",
        "labels = np.array(labels)\n",
        "y_true = labels.flatten() # True labels (0 or 1)\n",
        "\n",
        "models = {MODEL_R: model_rgb, MODEL_W: model_wavelets, MODEL_RW: model_rgb_wavelets}\n",
        "\n",
        "# Sample Selection\n",
        "pc_R = predictions[MODEL_R][\"pc\"]\n",
        "pc_W = predictions[MODEL_W][\"pc\"]\n",
        "pc_RW = predictions[MODEL_RW][\"pc\"]\n",
        "\n",
        "def select_samples(y_true, pc_A, pc_B, pred_A_correct, pred_B_correct, max_count):\n",
        "    A_is_correct = (pc_A == y_true)\n",
        "    B_is_correct = (pc_B == y_true)\n",
        "    condition = (A_is_correct == pred_A_correct) & (B_is_correct == pred_B_correct)\n",
        "    indices = np.where(condition)[0]\n",
        "\n",
        "    if len(indices) > max_count:\n",
        "        return random.sample(list(indices), max_count)\n",
        "    return list(indices)\n",
        "\n",
        "# Select samples for Figure A (RGB Only vs. Wavelets Only)\n",
        "chosen_A = {}\n",
        "chosen_A[\"W_Corrects_R\"] = select_samples(y_true, pc_R, pc_W, pred_A_correct=False, pred_B_correct=True, max_count=MAX_SAMPLES)\n",
        "chosen_A[\"R_Corrects_W\"] = select_samples(y_true, pc_R, pc_W, pred_A_correct=True, pred_B_correct=False, max_count=MAX_SAMPLES)\n",
        "chosen_A[\"Common_Failure\"] = select_samples(y_true, pc_R, pc_W, pred_A_correct=False, pred_B_correct=False, max_count=MAX_SAMPLES)\n",
        "\n",
        "# Select samples for Figure B (RGB Only vs. RGB + Wavelets)\n",
        "chosen_B = {}\n",
        "chosen_B[\"Fusion_Improved\"] = select_samples(y_true, pc_R, pc_RW, pred_A_correct=False, pred_B_correct=True, max_count=MAX_SAMPLES)\n",
        "chosen_B[\"Fusion_Degraded\"] = select_samples(y_true, pc_R, pc_RW, pred_A_correct=True, pred_B_correct=False, max_count=MAX_SAMPLES)\n",
        "chosen_B[\"Common_Success\"] = select_samples(y_true, pc_R, pc_RW, pred_A_correct=True, pred_B_correct=True, max_count=MAX_SAMPLES)\n",
        "\n",
        "# Consolidate all unique indices for Grad-CAM computation\n",
        "all_indices_to_compute = set()\n",
        "for indices in chosen_A.values(): all_indices_to_compute.update(indices)\n",
        "for indices in chosen_B.values(): all_indices_to_compute.update(indices)\n",
        "\n",
        "# Grad-CAM Pre-computation (Optimized Step)\n",
        "\n",
        "def precompute_data_and_gradcam(indices, paths, models, predictions, y_true, IMG_SIZE, LAST_CONV_LAYER_NAME):\n",
        "    precomputed_data = {}\n",
        "    all_model_names = list(models.keys())\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        p = paths[idx]\n",
        "        orig_img = keras.utils.img_to_array(keras.utils.load_img(p, target_size=IMG_SIZE)).astype(np.uint8)\n",
        "\n",
        "        gc_results = {}\n",
        "        for name in all_model_names:\n",
        "            m = models[name]\n",
        "            arr = get_processed_array(p, name, IMG_SIZE)\n",
        "\n",
        "            pv = predictions[name][\"pv\"][idx]\n",
        "            pc = predictions[name][\"pc\"][idx]\n",
        "\n",
        "            # Compute Grad-CAM only for the selected subset\n",
        "            heat = make_gradcam_heatmap(arr, m, LAST_CONV_LAYER_NAME, pred_index=pc).numpy()\n",
        "\n",
        "            gc_results[name] = {\"pv\": pv, \"pc\": pc, \"cm_name\": get_cm_name(y_true[idx], pc), \"heatmap\": heat}\n",
        "\n",
        "        precomputed_data[idx] = {\"orig\": orig_img, \"y_true\": y_true[idx], \"gc_data\": gc_results}\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Grad-CAM pre-computation finished in {end_time - start_time:.2f} seconds.\")\n",
        "    return precomputed_data\n",
        "\n",
        "# Execute the pre-computation\n",
        "precomputed_results = precompute_data_and_gradcam(list(all_indices_to_compute), paths, models, predictions, y_true, IMG_SIZE, LAST_CONV_LAYER_NAME)\n",
        "\n",
        "# Plotting\n",
        "\n",
        "def generate_figure(chosen_dict, precomputed_data, models_to_plot, title):\n",
        "    \"\"\"Generates the figure using precomputed data.\"\"\"\n",
        "\n",
        "    all_rows_data = []\n",
        "    row_titles = []\n",
        "    for group_title, indices in chosen_dict.items():\n",
        "        for idx in indices:\n",
        "            if idx in precomputed_data: # Ensure we only plot computed samples\n",
        "                all_rows_data.append(precomputed_data[idx])\n",
        "                row_titles.append(group_title)\n",
        "\n",
        "    # Calculate figure size dynamically\n",
        "    fig, axes = plt.subplots(len(all_rows_data), 1 + len(models_to_plot), figsize=(4 * (1 + len(models_to_plot)), 3 * len(all_rows_data)))\n",
        "\n",
        "    print(f\"\\nGenerating {title} with {len(all_rows_data)} rows...\")\n",
        "\n",
        "    for r, data in enumerate(all_rows_data):\n",
        "        group_title = row_titles[r]\n",
        "        orig = data['orig']\n",
        "        y_true_val = data['y_true']\n",
        "\n",
        "        # Original Image Column\n",
        "        axes[r, 0].imshow(orig)\n",
        "        axes[r, 0].set_title(f\"{group_title}\\nTrue={y_true_val}\", fontsize=8)\n",
        "        axes[r, 0].axis('off')\n",
        "\n",
        "        # Grad-CAM Columns\n",
        "        for c, name in enumerate(models_to_plot, start=1):\n",
        "            gc_data = data['gc_data'][name]\n",
        "            pv = gc_data['pv']\n",
        "            pc = gc_data['pc']\n",
        "            cm_name = gc_data['cm_name']\n",
        "            heat = gc_data['heatmap']\n",
        "\n",
        "            axes[r, c].imshow(overlay(orig, heat))\n",
        "            axes[r, c].set_title(f\"{name}\\n{cm_name} Pred={pv:.3f} C={pc}\", fontsize=8)\n",
        "            axes[r, c].axis('off')\n",
        "\n",
        "    fig.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
        "    plt.show()\n",
        "\n",
        "# Generate Figure A\n",
        "generate_figure(chosen_A, precomputed_results,\n",
        "                models_to_plot=[MODEL_R, MODEL_W],\n",
        "                title=\"Figure A: Independent Feature Comparison (RGB Only vs. Wavelets Only)\")\n",
        "\n",
        "# Generate Figure B\n",
        "generate_figure(chosen_B, precomputed_results,\n",
        "                models_to_plot=[MODEL_R, MODEL_RW],\n",
        "                title=\"Figure B: Feature Fusion Effect (RGB Only vs. RGB + Wavelets)\")"
      ],
      "metadata": {
        "id": "hfpRlBKWahrF"
      },
      "id": "hfpRlBKWahrF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_triple_samples(y_true, pc_R, pc_W, pc_RW, correct_R, correct_W, correct_RW, max_count):\n",
        "    \"\"\"Selects indices based on the correctness status of three models.\"\"\"\n",
        "    R_is_correct = (pc_R == y_true)\n",
        "    W_is_correct = (pc_W == y_true)\n",
        "    RW_is_correct = (pc_RW == y_true)\n",
        "\n",
        "    condition = (R_is_correct == correct_R) & \\\n",
        "                (W_is_correct == correct_W) & \\\n",
        "                (RW_is_correct == correct_RW)\n",
        "\n",
        "    indices = np.where(condition)[0]\n",
        "\n",
        "    if len(indices) > max_count:\n",
        "        return random.sample(list(indices), max_count)\n",
        "    return list(indices)\n",
        "\n",
        "chosen_comparison = {}\n",
        "\n",
        "chosen_comparison[\"Fusion_Win\"] = select_triple_samples(\n",
        "    y_true, pc_R, pc_W, pc_RW,\n",
        "    correct_R=False, correct_W=False, correct_RW=True,\n",
        "    max_count=MAX_SAMPLES\n",
        ")\n",
        "\n",
        "chosen_comparison[\"Wavelets_Only_Win\"] = select_triple_samples(\n",
        "    y_true, pc_R, pc_W, pc_RW,\n",
        "    correct_R=False, correct_W=True, correct_RW=False,\n",
        "    max_count=MAX_SAMPLES\n",
        ")\n",
        "\n",
        "chosen_comparison[\"Common_Failure\"] = select_triple_samples(\n",
        "    y_true, pc_R, pc_W, pc_RW,\n",
        "    correct_R=False, correct_W=False, correct_RW=False,\n",
        "    max_count=MAX_SAMPLES\n",
        ")\n",
        "\n",
        "\n",
        "all_indices_to_compute = set()\n",
        "for indices in chosen_comparison.values():\n",
        "    all_indices_to_compute.update(indices)\n",
        "\n",
        "print(f\"--- Step 3: Selection complete. {len(all_indices_to_compute)} unique samples chosen for triple comparison. ---\")\n",
        "\n",
        "# Grad-CAM Pre-computation\n",
        "\n",
        "# Execute the pre-computation\n",
        "precomputed_results = precompute_data_and_gradcam(\n",
        "    list(all_indices_to_compute), paths, models, predictions, y_true, IMG_SIZE, LAST_CONV_LAYER_NAME\n",
        ")\n",
        "\n",
        "# Plotting (Single Figure for Three Models)\n",
        "\n",
        "\n",
        "def generate_triple_figure(chosen_dict, precomputed_data, models_to_plot, title):\n",
        "\n",
        "    all_rows_data = []\n",
        "    row_titles = []\n",
        "    for group_title, indices in chosen_dict.items():\n",
        "        for idx in indices:\n",
        "            if idx in precomputed_data:\n",
        "                all_rows_data.append(precomputed_data[idx])\n",
        "                row_titles.append(group_title)\n",
        "\n",
        "    if not all_rows_data:\n",
        "        print(f\"Warning: No samples found for {title}.\")\n",
        "        return\n",
        "\n",
        "    # Figure size: 1 Original Image + 3 Models = 4 Columns\n",
        "    fig, axes = plt.subplots(len(all_rows_data), 1 + len(models_to_plot),\n",
        "                             figsize=(4 * (1 + len(models_to_plot)), 3 * len(all_rows_data)))\n",
        "\n",
        "    print(f\"\\nGenerating {title} with {len(all_rows_data)} rows...\")\n",
        "\n",
        "    for r, data in enumerate(all_rows_data):\n",
        "        group_title = row_titles[r]\n",
        "        orig = data['orig']\n",
        "        y_true_val = data['y_true']\n",
        "\n",
        "        # Original Image Column\n",
        "        axes[r, 0].imshow(orig)\n",
        "        axes[r, 0].set_title(f\"{group_title}\\nTrue={y_true_val}\", fontsize=8)\n",
        "        axes[r, 0].axis('off')\n",
        "\n",
        "        # Grad-CAM Columns (3 models)\n",
        "        for c, name in enumerate(models_to_plot, start=1):\n",
        "            gc_data = data['gc_data'][name]\n",
        "            pv = gc_data['pv']\n",
        "            pc = gc_data['pc']\n",
        "            cm_name = gc_data['cm_name']\n",
        "            heat = gc_data['heatmap']\n",
        "\n",
        "            axes[r, c].imshow(overlay(orig, heat))\n",
        "            axes[r, c].set_title(f\"{name}\\n{cm_name} Pred={pv:.3f} C={pc}\", fontsize=8)\n",
        "            axes[r, c].axis('off')\n",
        "\n",
        "    fig.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
        "    plt.show()\n",
        "\n",
        "# Generate the Triple Comparison Figure\n",
        "generate_triple_figure(chosen_comparison, precomputed_results,\n",
        "                       models_to_plot=[MODEL_R, MODEL_W, MODEL_RW],\n",
        "                       title=\"Figure C: Three-Model Comparison (Fusion Success, Degradation, and Failure)\")\n"
      ],
      "metadata": {
        "id": "AwUxFdCmfJoj"
      },
      "id": "AwUxFdCmfJoj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jm-ieRxOM7-Y",
      "metadata": {
        "id": "Jm-ieRxOM7-Y"
      },
      "outputs": [],
      "source": [
        "def get_processed_array(img_path: str, model_name: str, size: tuple):\n",
        "    img = keras.utils.load_img(img_path, target_size=size)\n",
        "    array = keras.utils.img_to_array(img)\n",
        "    raw_tensor = tf.constant(array[np.newaxis, ...], dtype=tf.uint8)\n",
        "\n",
        "    if 'Wavelets Only' in model_name:\n",
        "        processed_array, _ = preprocess_wavelet_only_valid(raw_tensor, tf.constant([0]))\n",
        "    elif 'RGB + Wavelets' in model_name:\n",
        "        processed_array, _ = preprocess_rgb_wavelet_valid(raw_tensor, tf.constant([0]))\n",
        "    else:\n",
        "        processed_array, _ = preprocess_rgb_only_valid(raw_tensor, tf.constant([0]))\n",
        "\n",
        "    return processed_array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    \"\"\"Computes Grad-CAM heatmap, returns a TensorFlow Tensor.\"\"\"\n",
        "\n",
        "    _ = model(img_array)\n",
        "\n",
        "    grad_model = keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_array)\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.cast(tf.round(predictions[0]), tf.int32)\n",
        "\n",
        "        if pred_index == 1:\n",
        "            class_channel = predictions[:, 0]\n",
        "        else:\n",
        "            class_channel = 1.0 - predictions[:, 0]\n",
        "\n",
        "        class_channel = tf.expand_dims(class_channel, axis=-1)\n",
        "\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    heatmap = conv_outputs @ tf.cast(pooled_grads, conv_outputs.dtype)[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-7)\n",
        "    return heatmap\n",
        "\n",
        "def overlay(orig, heat, alpha=0.5):\n",
        "    h = np.uint8(255*np.clip(heat,0,1))\n",
        "    cmap = np.uint8(cm.get_cmap(\"jet\")(np.arange(256))[:,:3]*255)[h]\n",
        "    cmap = np.array(Image.fromarray(cmap).resize((orig.shape[1], orig.shape[0]), Image.BILINEAR))\n",
        "    return np.clip(cmap*alpha + orig*(1-alpha),0,255).astype(np.uint8)\n",
        "\n",
        "# Helper to get Confusion Matrix name (CM name)\n",
        "def get_cm_name(y_true, pc):\n",
        "    if y_true == 1 and pc == 1: return \"TP\"\n",
        "    if y_true == 0 and pc == 1: return \"FP\"\n",
        "    if y_true == 0 and pc == 0: return \"TN\"\n",
        "    if y_true == 1 and pc == 0: return \"FN\"\n",
        "    return \"Unknown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbPopctdCd_A",
      "metadata": {
        "id": "cbPopctdCd_A"
      },
      "outputs": [],
      "source": [
        "test_dir = os.path.join(dataset_dir, \"test\")\n",
        "paths, labels = [], []\n",
        "for cls, d in enumerate(sorted(os.listdir(test_dir))):\n",
        "    folder = os.path.join(test_dir, d)\n",
        "    for f in sorted(os.listdir(folder)):\n",
        "        if f.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "            paths.append(os.path.join(folder, f)); labels.append(cls)\n",
        "paths = np.array(paths); labels = np.array(labels)\n",
        "y = labels\n",
        "chosen = {}\n",
        "while len(chosen) < 4:\n",
        "    idx = random.randint(0, len(paths)-1)\n",
        "    arr_ref = get_processed_array(paths[idx], REF, IMG_SIZE)\n",
        "    pv_ref = float(models[REF].predict(arr_ref, verbose=0).ravel()[0])\n",
        "    pc_ref = int(pv_ref >= 0.5)\n",
        "    if 'TP' not in chosen and y[idx]==1 and pc_ref==1: chosen['TP'] = idx\n",
        "    if 'TN' not in chosen and y[idx]==0 and pc_ref==0: chosen['TN'] = idx\n",
        "    if 'FP' not in chosen and y[idx]==0 and pc_ref==1: chosen['FP'] = idx\n",
        "    if 'FN' not in chosen and y[idx]==1 and pc_ref==0: chosen['FN'] = idx\n",
        "\n",
        "rows = ['TP','FP','TN','FN']\n",
        "models_list = list(models.keys())\n",
        "\n",
        "fig, axes = plt.subplots(4, 1+len(models_list), figsize=(4*(1+len(models_list)),16))\n",
        "for r, key in enumerate(rows):\n",
        "    idx = chosen[key]\n",
        "    p = paths[idx]\n",
        "    orig = keras.utils.img_to_array(keras.utils.load_img(p, target_size=IMG_SIZE)).astype(np.uint8)\n",
        "    axes[r,0].imshow(orig)\n",
        "    axes[r,0].set_title(f\"{key}\\nTrue={y[idx]}\")\n",
        "    axes[r,0].axis('off')\n",
        "\n",
        "    for c, name in enumerate(models_list, start=1):\n",
        "        m = models[name]\n",
        "        arr = get_processed_array(p, name, IMG_SIZE)\n",
        "        pv = float(m.predict(arr, verbose=0).ravel()[0])\n",
        "        pc = int(pv>=0.5)\n",
        "        heat = make_gradcam_heatmap(arr, m, LAST_CONV_LAYER_NAME, pred_index=pc).numpy()\n",
        "        axes[r,c].imshow(overlay(orig, heat))\n",
        "        axes[r,c].set_title(f\"{name}\\nPred={pv:.3f} C={pc}\")\n",
        "        axes[r,c].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}